<!-- build time:Sun Apr 18 2021 15:00:01 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="个人博客" href="http://example.com/rss.xml"><link rel="alternate" type="application/atom+xml" title="个人博客" href="http://example.com/atom.xml"><link rel="alternate" type="application/json" title="个人博客" href="http://example.com/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="http://example.com/%E9%BE%99%E8%8A%AF3A2000%E7%A7%BB%E6%A4%8DHadoop%E6%8C%87%E5%8D%97/"><title>龙芯 3A2000 移植 Hadoop 指南 | 红蓝一生伴 = 个人博客 = 喵喵喵</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">龙芯 3A2000 移植 Hadoop 指南</h1><div class="meta"><span class="item" title="创建时间：2021-04-10 13:31:30"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2021-04-10T13:31:30+08:00">2021-04-10</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>17k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>15 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">红蓝一生伴</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclflwv2aj20zk0m84qp.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicm07ih54j20zk0m84qp.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipex2cdtbj20zk0m8x6p.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclh0m9pdj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipexoj0moj20zk0m8kgu.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclg5ms2rj20zk0m8u0x.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://example.com/%E9%BE%99%E8%8A%AF3A2000%E7%A7%BB%E6%A4%8DHadoop%E6%8C%87%E5%8D%97/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="红蓝一生伴"><meta itemprop="description" content="喵喵喵, 喵喵喵"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="个人博客"></span><div class="body md" itemprop="articleBody"><h1 id="一-hadoop-简介"><a class="anchor" href="#一-hadoop-简介">#</a> 一、hadoop 简介</h1><p>hadoop 是一个由 Apache 基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。</p><p>龙芯 3A2000 上运行 Hadoop<br>hadoop 实现了一个分布式文件系统（hadoop Distributed File System），简称 HDFS。HDFS 有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS 放宽了（relax）POSIX 的要求，可以以流的形式访问（streaming access）文件系统中的数据。</p><p>hadoop 的框架最核心的设计就是：HDFS 和 MapReduce。HDFS 为海量的数据提供了存储，则 MapReduce 为海量的数据提供了计算。</p><p>hadoop 是一个能够对大量数据进行分布式处理的软件框架，它以一种可靠、高效、可伸缩的方式进行数据处理。维护多个工作数据副本，确保能够针对失败的节点重新分布处理。并行工作方式，提高处理速度，之处处理 PB 级数据。<br>hadoop 是一个能够让用户轻松架构和使用的分布式计算平台。用户可以轻松地在 hadoop 上开发和运行处理海量数据的应用程序。它主要有以下几个优点：</p><p>高可靠性: hadoop 按位存储和处理数据的能力值得人们信赖。<br>高扩展性: hadoop 是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。<br>高效性: hadoop 能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。<br>高容错性:hadoop 能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。<br>低成本：与一体机、商用数据仓库以及 QlikView、Yonghong Z-Suite 等数据集市相比，hadoop 是开源的，项目的软件成本因此会大大降低。<br>本文主要涉及以下内容：hadoop 源码编译，hadoop 在分布式计算云存储系统中的部署和应用，同时也将记录 hadoop 搭建过程的 FAQ 和相对解决方案。<br>hadoop 集群 (cluster) 支持如下 3 种操作模式：</p><p>Local/Standalone Mode： 完成下载后，默认情况下 hadoop 被配置为 Standalone 模式，作为单个 Java</p><p>Pseudo Distributed Mode<br>此种模式下，每个 hadoop 守护进程，如 hdfs,yarn,MapReduce 等分布式部署在不同的机器上，分别作为独立的 Java 进程，这种模式有助于开发。</p><p>Fully Distributed Mode<br>完全分布式部署，需要至少 2 台机器，作为一个集群，稍后进行详解。</p><h1 id="二-移植环境"><a class="anchor" href="#二-移植环境">#</a> 二、移植环境</h1><p>首先给出本机的软硬件信息，<br>软件环境：<br>(1) loongnix1.0 系统（2016.8.10 版本）。下载地址 <span class="exturl" data-url="aHR0cDovL3d3dy5sb29uZ25peC5vcmc=">www.loongnix.org</span><br>(2) 内核版本：3.10.84-all<br>(3) JDK 版本：1.8.0_25-rc16-b17 or later<br>(4)MAVEN:3.2.2 or later</p><p>硬件环境:<br>(1) 开发板类型: Loongson-3B-780E-2w-V0.2-demo<br>(2) 固件版本: loongson-PMON-V3.3.0</p><p>本例中使用的 hadoop 的版本为 2.7.2, hadoop 源码下载地址，参见附录中的”hadoop downloads” 链接。hadoop 编译依赖 findbugs 和 cmake 软件包，建议在编译前通过 yum 命令进行自动安装，安装方式如下:</p><p>[hadoop@localhost log]$ sudo yum -y install java-1.8.0-openjdk-devel java-1.8.0-openjdk-headless \ java-1.8.0-openjdk findbugs cmake protobuf-compiler<br>完成安装后，需要设置如下环境变量，建议将以下内容追加到 /et c/profile 文件，并用 source 命令使其生效。</p><p>export FINDBUGS_HOME=/usr/share/findbugs<br>export MAVEN_HOME=/usr/share/maven<br>export MAVEN_OPTS=&quot;-Xms256m -Xmx512m&quot;<br>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.25-5.rc16.fc21.loongson.m<br>PATH=/usr/lib64/ccache:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/h<br>export PATH=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>A</mi><mi>T</mi><mi>H</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">PATH:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:.13889em">T</span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span></span>JAVA_HOME/bin:$MAVEN_HOME/bin<br>Build From Scratch：首先解压源码到自定义目录 (本例采用 /usr/local) 利用 mvn</p><p>clean package -Pdist,native,src -DskipTests -Dtar 命令进行编译。<br>tar xvf hadoop-2.7.2.src.gz -C mkdir /usr/local/<br>cd /usr/local/hadoop-2.7.2<br>mvn clean package -Pdist,native,src -DskipTests -Dtar</p><h1 id="三-注意事项"><a class="anchor" href="#三-注意事项">#</a> 三、注意事项</h1><p>(1) 本例中采用 /usr/local 作为工作目录需要 root 权限<br>(2) 编译过程报错，可参见对应 FAQ, 问题解决后，通过 mvn package -Pdist,native,src -DskipTests -Dtar 命令再次启动编译。<br>(3) FAQ 的标识由序号 (从 001 开始) 和模块名组成，其中者通过冒号间隔。模块名源自 maven Reactor 涉及的 modules 名称。</p><h1 id="四-faq"><a class="anchor" href="#四-faq">#</a> 四、FAQ</h1><p>001:Apache hadoop Common<br>终端报错:</p><h1><a class="anchor" href="#">#</a></h1><h1 id="a-fatal-error-has-been-detected-by-the-java-runtime-environment"><a class="anchor" href="#a-fatal-error-has-been-detected-by-the-java-runtime-environment">#</a> A fatal error has been detected by the Java Runtime Environment:</h1><h1 id="-2"><a class="anchor" href="#-2">#</a></h1><h1 id="sigsegv-0xb-at-pc0x000000ffe18f46fc-pid5300-tid1099154321904"><a class="anchor" href="#sigsegv-0xb-at-pc0x000000ffe18f46fc-pid5300-tid1099154321904">#</a> SIGSEGV (0xb) at pc=0x000000ffe18f46fc, pid=5300, tid=1099154321904</h1><h1 id="-3"><a class="anchor" href="#-3">#</a></h1><h1 id="jre-version-openjdk-runtime-environment-80_25-b17-build-180_25-rc16-b17"><a class="anchor" href="#jre-version-openjdk-runtime-environment-80_25-b17-build-180_25-rc16-b17">#</a> JRE version: OpenJDK Runtime Environment (8.0_25-b17) (build 1.8.0_25-rc16-b17)</h1><h1 id="java-vm-openjdk-64-bit-server-vm-2525-b02-mixed-mode-linux-compressed-oops"><a class="anchor" href="#java-vm-openjdk-64-bit-server-vm-2525-b02-mixed-mode-linux-compressed-oops">#</a> Java VM: OpenJDK 64-Bit Server VM (25.25-b02 mixed mode linux- compressed oops)</h1><h1 id="problematic-frame"><a class="anchor" href="#problematic-frame">#</a> Problematic frame:</h1><h1 id="j-62748-c2-scalatoolsasmclasswritergetlscalatoolsasmitemlscalatoolsasmitem-49-bytes-0x000000ffe18f46fc-0x000000ffe18f46a00x5c"><a class="anchor" href="#j-62748-c2-scalatoolsasmclasswritergetlscalatoolsasmitemlscalatoolsasmitem-49-bytes-0x000000ffe18f46fc-0x000000ffe18f46a00x5c">#</a> J 62748 C2 scala.tools.asm.ClassWriter.get(Lscala/tools/asm/Item;)Lscala/tools/asm/Item; (49 bytes) @ 0x000000ffe18f46fc [0x000000ffe18f46a0+0x5c]</h1><h1 id="-4"><a class="anchor" href="#-4">#</a></h1><h1 id="failed-to-write-core-dump-core-dumps-have-been-disabled-to-enable-core-dumping-try-ulimit-c-unlimited-before-starting-java-again"><a class="anchor" href="#failed-to-write-core-dump-core-dumps-have-been-disabled-to-enable-core-dumping-try-ulimit-c-unlimited-before-starting-java-again">#</a> Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again</h1><h1 id="-5"><a class="anchor" href="#-5">#</a></h1><h1 id="if-you-would-like-to-submit-a-bug-report-please-visit"><a class="anchor" href="#if-you-would-like-to-submit-a-bug-report-please-visit">#</a> If you would like to submit a bug report, please visit:</h1><h1 id="httpbugreportsuncombugreportcrashjsp"><a class="anchor" href="#httpbugreportsuncombugreportcrashjsp">#</a> <span class="exturl" data-url="aHR0cDovL2J1Z3JlcG9ydC5zdW4uY29tL2J1Z3JlcG9ydC9jcmFzaC5qc3A=">http://bugreport.sun.com/bugreport/crash.jsp</span></h1><p>解决方法:<br>此问题与 JDK 的并行 GC 相关，编译 hadoop 和 spark 均有遇到，目前的解决方法：调整 /etc/profile 文件 MAVEN_OPTS 环境变量为如下内容:</p><p>export MAVEN_OPTS=&quot;-Xms3560m -Xmx3560m -XX:-UseParallelGC -XX:-UseParallelOldGC&quot;<br>002: any-modules<br>终端现象: maven 编译过程中构件 (xxx.jar 和 xxx.pom) 无法下载。<br>解决方法：打开 maven 配置文件的代理设置选项，并重新安装 ca-certificates<br># 为 maven 设置代理</p><p>&lt;proxies&gt;<br>&lt;!-- proxy<br>| Specification for one proxy, to be used in connecting to the network.<br>|--&gt;<br>&lt;proxy&gt;<br>&lt;id&gt;proxy01&lt;/id&gt;<br>&lt;active&gt;true&lt;/active&gt;<br>&lt;protocol&gt;http&lt;/protocol&gt;<br>&lt;host&gt;ip_address&lt;/host&gt;<br>&lt;port&gt;port&lt;/port&gt;<br>&lt;nonProxyHosts&gt;localhost&lt;/nonProxyHosts&gt;<br>&lt;/proxy&gt;<br>&lt;proxy&gt;<br>&lt;id&gt;proxy02&lt;/id&gt;<br>&lt;active&gt;true&lt;/active&gt;<br>&lt;protocol&gt;https&lt;/protocol&gt;<br>&lt;host&gt;ip_address&lt;/host&gt;<br>&lt;port&gt;port&lt;/port&gt;<br>&lt;nonProxyHosts&gt;localhost&lt;/nonProxyHosts&gt;<br>&lt;/proxy&gt;<br>&lt;/proxies&gt;<br># 重新安装 ca-certificates<br>Sudo yum -y install ca-certificates</p><p>注意事项：凡出现 Maven 编译过程构件无法下载，均可参考本 FAQ 内容进行适当修改。</p><h1 id="五-编译结果"><a class="anchor" href="#五-编译结果">#</a> 五、编译结果</h1><p>Maven 编译通过后，将在终端显示 hadoop 的 maven Reactor (本次编译的所有 maven 模块) 和编译时间信息。下面给出的时耗信息，进攻参考不同软硬件平台将会产生差异。</p><p>[INFO] ------------------------------------------------------------------------<br>[INFO] Reactor Summary:<br>[INFO]<br>[INFO] Apache hadoop Main ................................. SUCCESS [ 10.769 s]<br>[INFO] Apache hadoop Project POM .......................... SUCCESS [ 8.793 s]<br>[INFO] Apache hadoop Annotations .......................... SUCCESS [ 18.834 s]<br>[INFO] Apache hadoop Assemblies ........................... SUCCESS [ 2.414 s]<br>[INFO] Apache hadoop Project Dist POM ..................... SUCCESS [ 9.653 s]<br>[INFO] Apache hadoop Maven Plugins ........................ SUCCESS [ 25.215 s]<br>[INFO] Apache hadoop MiniKDC .............................. SUCCESS [ 20.682 s]<br>[INFO] Apache hadoop Auth ................................. SUCCESS [ 26.240 s]<br>[INFO] Apache hadoop Auth Examples ........................ SUCCESS [ 23.112 s]<br>[INFO] Apache hadoop Common ............................... SUCCESS [45:23 min]<br>[INFO] Apache hadoop NFS .................................. SUCCESS [ 45.079 s]<br>[INFO] Apache hadoop KMS .................................. SUCCESS [01:27 min]<br>[INFO] Apache hadoop Common Project ....................... SUCCESS [ 1.104 s]<br>[INFO] Apache hadoop HDFS ................................. SUCCESS [21:45 min]<br>[INFO] Apache hadoop HttpFS ............................... SUCCESS [02:13 min]<br>[INFO] Apache hadoop HDFS BookKeeper Journal .............. SUCCESS [ 47.832 s]<br>[INFO] Apache hadoop HDFS-NFS ............................. SUCCESS [ 34.029 s]<br>[INFO] Apache hadoop HDFS Project ......................... SUCCESS [ 1.075 s]<br>[INFO] hadoop-yarn ........................................ SUCCESS [ 1.354 s]<br>[INFO] hadoop-yarn-api .................................... SUCCESS [07:20 min]<br>[INFO] hadoop-yarn-common ................................. SUCCESS [35:51 min]<br>[INFO] hadoop-yarn-server ................................. SUCCESS [ 1.020 s]<br>[INFO] hadoop-yarn-server-common .......................... SUCCESS [01:42 min]<br>[INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [01:58 min]<br>[INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [ 25.288 s]<br>[INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [01:05 min]<br>[INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [02:52 min]<br>[INFO] hadoop-yarn-server-tests ........................... SUCCESS [ 40.356 s]<br>[INFO] hadoop-yarn-client ................................. SUCCESS [ 54.780 s]<br>[INFO] hadoop-yarn-server-sharedcachemanager .............. SUCCESS [ 24.110 s]<br>[INFO] hadoop-yarn-applications ........................... SUCCESS [ 1.017 s]<br>[INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [ 21.223 s]<br>[INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [ 17.608 s]<br>[INFO] hadoop-yarn-site ................................... SUCCESS [ 1.145 s]<br>[INFO] hadoop-yarn-registry ............................... SUCCESS [ 42.659 s]<br>[INFO] hadoop-yarn-project ................................ SUCCESS [ 34.614 s]<br>[INFO] hadoop-mapreduce-client ............................ SUCCESS [ 1.905 s]<br>[INFO] hadoop-mapreduce-client-core ....................... SUCCESS [33:18 min]<br>[INFO] hadoop-mapreduce-client-common ..................... SUCCESS [32:57 min]<br>[INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [ 28.868 s]<br>[INFO] hadoop-mapreduce-client-app ........................ SUCCESS [01:00 min]<br>[INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [ 46.223 s]<br>[INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 29.643 s]<br>[INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [ 15.580 s]<br>[INFO] Apache hadoop MapReduce Examples ................... SUCCESS [ 40.229 s]<br>[INFO] hadoop-mapreduce ................................... SUCCESS [ 24.719 s]<br>[INFO] Apache hadoop MapReduce Streaming .................. SUCCESS [ 33.669 s]<br>[INFO] Apache hadoop Distributed Copy ..................... SUCCESS [ 59.792 s]<br>[INFO] Apache hadoop Archives ............................. SUCCESS [ 19.986 s]<br>[INFO] Apache hadoop Rumen ................................ SUCCESS [ 47.303 s]<br>[INFO] Apache hadoop Gridmix .............................. SUCCESS [ 30.258 s]<br>[INFO] Apache hadoop Data Join ............................ SUCCESS [ 22.306 s]<br>[INFO] Apache hadoop Ant Tasks ............................ SUCCESS [ 19.212 s]<br>[INFO] Apache hadoop Extras ............................... SUCCESS [ 27.362 s]<br>[INFO] Apache hadoop Pipes ................................ SUCCESS [ 6.723 s]<br>[INFO] Apache hadoop OpenStack support .................... SUCCESS [ 34.857 s]<br>[INFO] Apache hadoop Amazon Web Services support .......... SUCCESS [ 37.631 s]<br>[INFO] Apache hadoop Azure support ........................ SUCCESS [ 30.848 s]<br>[INFO] Apache hadoop Client ............................... SUCCESS [01:02 min]<br>[INFO] Apache hadoop Mini-Cluster ......................... SUCCESS [ 3.409 s]<br>[INFO] Apache hadoop Scheduler Load Simulator ............. SUCCESS [ 33.821 s]<br>[INFO] Apache hadoop Tools Dist ........................... SUCCESS [ 55.501 s]<br>[INFO] Apache hadoop Tools ................................ SUCCESS [ 0.768 s]<br>[INFO] Apache hadoop Distribution ......................... SUCCESS [03:44 min]<br>[INFO] ------------------------------------------------------------------------<br>[INFO] BUILD SUCCESS<br>[INFO] ------------------------------------------------------------------------<br>[INFO] Total time: 03:33 h<br>[INFO] Finished at: 2016-08-01T14:22:17+08:00<br>[INFO] Final Memory: 125M/3096M<br>[INFO] ------------------------------------------------------------------------<br>本例的编译结果位于 /usr/local/hadoop-2.7.2/hadoop-dist/target/ 目录，源码包和二进制包分别为 hadoop-2.7.2-src.tar.gz 和 hadoop-2.7.2.tar.gz。至此 hadoop 编译结束。</p><h1 id="六-hadoop-集群搭建测试"><a class="anchor" href="#六-hadoop-集群搭建测试">#</a> 六、Hadoop 集群搭建测试</h1><p>本节采用 hadoop ”Fully Distributed Mode” 工作模式，在 IP 地址分别为 10.20.42.22 (slave1),10.20.42.22 (slave2),10.20.42.199 (master) 的机器上部署 3 节点的 hadoop 集群。</p><p>设置 SSH 免密码登录<br>SSH 免密码登录，假设使用 root 用户，在每台服务器都生成公钥，再合并到 authorized_keys，具体操作如下：<br>(1) fadora21 默认没有启动 ssh 无密登录，修改 /etc/ssh/sshd_config 注释掉以下 2 行。(每台机器都要设置)<br>#RSAAuthentication yes<br>#PubkeyAuthentication yes<br>(2) 在集群中的每台机器上，打开 shell 终端输入命令，ssh-keygen -t rsa，生成 key，不要输入密码，一直回车，/root 就会生成.ssh 文件夹，这个文件一般是隐藏的。(每台服务器都要设置)</p><p>(3) 合并 slave 节点的公钥到 authorized_keys 文件。在 Master 服务器，进入 /root/.ssh 目录，使用如下命令:<br>cat id_rsa.pub&gt;&gt; authorized_keys<br>ssh <span class="exturl" data-url="bWFpbHRvOnJvb3RAMTAuMjAuNDIuMjI=">root@10.20.42.22</span> cat ~/.ssh/id_rsa.pub&gt;&gt; authorized_keys<br>ssh <span class="exturl" data-url="bWFpbHRvOnJvb3RAMTAuMjAuNDIuMTA=">root@10.20.42.10</span> cat ~/.ssh/id_rsa.pub&gt;&gt; authorized_keys</p><p>(4) 把 Master 服务器的 authorized_keys、known_hosts 复制到 Slave 服务器的 /root/.ssh 目录</p><p>(5) 终端输入 ssh root@10.20.42.22 和 ssh root@10.20.42.10 进行验证是否免密登陆配置成功</p><p>搭建 hadoop 3 节点集群<br>搭建思路：准备 1 台主服务器和 2 台从服务器，从主服务器可以 ssh 免密登录从服务器器。hadoop 压缩包采用上节编译结果:hadoop-2.7.2.tar.gz。 3 台服务器的概要信息如下:<br>Master 10.20.42.199<br>Slave1 10.20.42.22<br>Slave2 10.20.42.10<br>搭建前提：服务器需要安装 JDK 并设置好 JAVA_HOM 等环境变量。可参考下面的例子:</p><p>#编辑 /etc/profile 文件并设置 JAVA_HOME 等环境变量<br>vi /etc/profile<br>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.25-6.b17.rc16.fc21.loongson.mips64el<br>export CLASSPATH=.:<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mi>A</mi><mi>V</mi><msub><mi>A</mi><mi>H</mi></msub><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">/</mi><mi>j</mi><mi>r</mi><mi>e</mi><mi mathvariant="normal">/</mi><mi>l</mi><mi>i</mi><mi>b</mi><mi mathvariant="normal">/</mi><mi>r</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>j</mi><mi>a</mi><mi>r</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">JAVA_HOME/jre/lib/rt.jar:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.09618em">J</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:.02778em">O</span><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">e</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">b</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">:</span></span></span></span>JAVA_HOME/lib/dt.jar:<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mi>A</mi><mi>V</mi><msub><mi>A</mi><mi>H</mi></msub><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">/</mi><mi>l</mi><mi>i</mi><mi>b</mi><mi mathvariant="normal">/</mi><mi>t</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>s</mi><mi mathvariant="normal">.</mi><mi>j</mi><mi>a</mi><mi>r</mi><mi>e</mi><mi>x</mi><mi>p</mi><mi>o</mi><mi>r</mi><mi>t</mi><mi>P</mi><mi>A</mi><mi>T</mi><mi>H</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">JAVA_HOME/lib/tools.jar export PATH=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.09618em">J</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.08125em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:.02778em">O</span><span class="mord mathnormal" style="margin-right:.10903em">M</span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">b</span><span class="mord">/</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="mord mathnormal">s</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:.13889em">T</span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span></span></span></span>PATH:$JAVA_HOME/bin<br># 使环境变量生效 并且验证 jdk 是否生效<br>source /etc/profile &amp;&amp; java -version<br>开始搭建<br>解压 hadoop-2.7.2.tar.gz 软件包，笔者的工作目录为 /home/loongson/, 没有特殊说明下面的配置文件均来自 master 服务器。</p><p>(1) 解压 hadoop 软件包: tar -xvf hadoop-2.7.2.tar.gz -C /home/loongson</p><p>(2) 在 /home/loongson/hadoop-2.7.2 目录下手动创建 tmp、hdfs、hdfs/data、hdfs/name 文件夹。</p><p>(3) 配置 /home/hadoop/hadoop-2.7.2/etc/hadoop 目录下的 core-site.xml (ip 设置成 master 的地址)</p><p>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;fs.defaultFS&lt;/name&gt;<br>&lt;value&gt;hdfs://10.20.42.199:9000&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>&lt;value&gt;file:/home/loongson/hadoop/tmp&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;io.file.buffer.size&lt;/name&gt;<br>&lt;value&gt;131702&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;<br>(4) 配置 /home/loongson/hadoop-2.7.2/etc/hadoop 目录下的 hdfs-site.xml (ip 设置成 master 的地址)</p><p>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br>&lt;value&gt;file:/home/loongson/hadoop/dfs/name&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br>&lt;value&gt;file:/home/loongson/hadoop/dfs/data&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.replication&lt;/name&gt;<br>&lt;value&gt;2&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:9001&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;<br>&lt;value&gt;true&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;<br>(5) 配置 /home/loongson/hadoop-2.7.2/etc/hadoop 目录下的 mapred-site.xml.template (ip 设置成 master 的地址)</p><p>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>&lt;value&gt;yarn&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:10020&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:19888&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;<br>(6) 配置 /home/loongson/hadoop-2.7.2/etc/hadoop 目录下的 yarn-site.xml (ip 设置成 master 的地址)</p><p>&lt;configuration&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>&lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt;<br>&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:8032&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:8030&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:8031&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:8033&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;<br>&lt;value&gt;10.20.42.199:8088&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;<br>&lt;value&gt;768&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;/configuration&gt;<br>(7) 修改位于 /home/loongson/hadoop-2.7.2/etc/hadoop 目录 hadoop-env.sh,yarn-env.sh 中的 JAVA_HOME 等环境变量。</p><p>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.25-6.b17.rc16.fc21.loongson.mips64el<br>(8) 配置 /home/loongson/hadoop-2.7.2/etc/hadoop 目录下的 slaves 文件，增加 2 个从 slave 节点，</p><p>10.20.42.10<br>10.20.42.22<br>(9) 将上述配置好的 Hadoop-2.7.2 (位于 master 机器上) 使用 scp 复制到各个 slave 节点对应位置上</p><p>scp -r /home/loongson/hadoop-2.7.2 10.20.42.10:/home/loongson<br>scp -r /home/loongson/hadoop-2.7.2 10.20.42.22:/home/loongson<br>(10) 在 Master 服务器启动 hadoop，从节点会自动启动，进入 /home/loongson/hadoop-2.7.2 目录</p><p>(1) 关闭机器防火墙:service iptables stop (主从都设置)</p><p>(2) 初始化 node 节点:bin/hdfs namenode -format</p><p>(3) 启动全部 node: sbin/start-all.sh<br>This script is Deprecated. Instead use <span class="exturl" data-url="aHR0cDovL3N0YXJ0LWRmcy5zaA==">start-dfs.sh</span> and <span class="exturl" data-url="aHR0cDovL3N0YXJ0LXlhcm4uc2g=">start-yarn.sh</span><br>16/09/02 08:49:56 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform...<br>using builtin-java classes where applicable<br>Starting namenodes on [hadoop-master-001]<br>hadoop-master-001: starting namenode, logging to /home/loongson/hadoop-2.7.2/logs/hadoop-root-namenode-<br>localhost.localdomain.out<br>10.20.42.22: starting datanode, logging to /home/loongson/hadoop-2.7.2/logs/hadoop-root-datanode-localhost.localdomain.out<br>10.20.42.22: /home/loongson/hadoop-2.7.2/bin/hdfs: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.25-6.b17.rc16.fc21.loongson.mips64el<br>10.20.42.22: /home/loongson/hadoop-2.7.2/bin/hdfs: line 304: /usr/lib/jvm/java-1.8.0-<br>openjdk-1.8.0.25-6.b17.rc16.fc21.loongson.mips64el/bin/java: 成功<br>10.20.42.10: starting datanode, logging to /home/loongson/hadoop-2.7.2/logs/hadoop-root-datanode-localhost.localdomain.out<br>Starting secondary namenodes [hadoop-master-001]<br>hadoop-master-001: secondarynamenode running as process 18418. Stop it first.<br>16/09/02 08:50:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java<br>classes where applicable<br>starting yarn daemons<br>resourcemanager running as process 16937. Stop it first.<br>10.20.42.10: starting nodemanager, logging to /home/loongson/hadoop-2.7.2/logs/yarn-root-nodemanager-localhost.localdomain.out<br>10.20.42.22: starting nodemanager, logging to /home/loongson/hadoop-2.7.2/logs/yarn-root-nodemanager-localhost.localdomain.out<br>10.20.42.22: /home/loongson/hadoop-2.7.2/bin/yarn: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.25-6.b17.rc16.fc21.loongson.mips64el<br>10.20.42.22: /home/loongson/hadoop-2.7.2/bin/yarn: line 333: /usr/lib/jvm/java-1.8.0-<br>openjdk-1.8.0.25-6.b17.rc16.fc21.loongson.mips64el/bin/java: 成功<br>(4) 暂停全部节点的命令: sbin/stop-all.sh</p><p>(5) 输入 jps 命令：如果从节点和主节点显示类似如下，说明节点搭建成功</p><p>master:<br>32497 OServerMain<br>3506 SecondaryNameNode<br>3364 DataNode<br>5654 Jps<br>2582 OGremlinConsole<br>16937 ResourceManager<br>3263 NameNode<br>slaves:<br>21580 Jps<br>20622 DataNode<br>(11) 从浏览器访问: <span class="exturl" data-url="aHR0cDovLzEwLjIwLjQyLjE5OTo4MDg4LyVFNiU4OCU5Nmh0dHA6Ly8xMC4yMC40Mi4xOTk6NTAwNzAv">http://10.20.42.199:8088 / 或 http://10.20.42.199:50070/</span> 查看 hadop 运行情况。下面给出从浏览器打开，看到的 hadoop 的运行情况截图:<br>Hadoop 运行预览和概要信息:</p><p>Hadoop 运行情况:</p><h1 id="七-下载成品"><a class="anchor" href="#七-下载成品">#</a> 七、下载成品</h1><p>如果觉得上面的移植过程太复杂，笔者已经准备好了移植完的二进制，可以直接下载运行：<br><span class="exturl" data-url="aHR0cDovL3d3dy5sb29uZ25peC5vcmcvaW5kZXgucGhwL0FwYWNoZV9oYWRvb3AtMi43LjI=">http://www.loongnix.org/index.php/Apache_hadoop-2.7.2</span></p><h1 id="八-总结"><a class="anchor" href="#八-总结">#</a> 八、总结</h1><p>hadoop-2.7.2 在 loongnix1.0 系统上正确完成源码编译和搭建小集群测试，可以作为开发者移植 hadoop 和进行集群测试的示范过程。</p></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2021-04-18 14:59:38" itemprop="dateModified" datetime="2021-04-18T14:59:38+08:00">2021-04-18</time> </span><span id="龙芯3A2000移植Hadoop指南/" class="item leancloud_visitors" data-flag-title="龙芯 3A2000 移植 Hadoop 指南" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="红蓝一生伴 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="红蓝一生伴 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="红蓝一生伴 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>红蓝一生伴 <i class="ic i-at"><em>@</em></i>个人博客</li><li class="link"><strong>本文链接：</strong> <a href="http://example.com/%E9%BE%99%E8%8A%AF3A2000%E7%A7%BB%E6%A4%8DHadoop%E6%8C%87%E5%8D%97/" title="龙芯 3A2000 移植 Hadoop 指南">http://example.com/龙芯3A2000移植Hadoop指南/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/%E5%8D%8E%E4%B8%BA%E9%B2%B2%E9%B9%8F%E4%BA%91%E4%B9%8B%E6%88%91%E8%A7%81/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclhnx9glj20zk0m8npd.jpg" title="华为鲲鹏云之我见"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>华为鲲鹏云之我见</h3></a></div><div class="item right"><a href="/%E9%BE%99%E6%97%8F%E7%BB%8F%E5%85%B8%E8%AF%AD%E5%BD%95/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipeybxm1pj20zk0m8niv.jpg" title="龙族经典语录"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>龙族经典语录</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80-hadoop-%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">一、hadoop 简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C-%E7%A7%BB%E6%A4%8D%E7%8E%AF%E5%A2%83"><span class="toc-number">2.</span> <span class="toc-text">二、移植环境</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89-%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">3.</span> <span class="toc-text">三、注意事项</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9B-faq"><span class="toc-number">4.</span> <span class="toc-text">四、FAQ</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#a-fatal-error-has-been-detected-by-the-java-runtime-environment"><span class="toc-number">6.</span> <span class="toc-text">A fatal error has been detected by the Java Runtime Environment:</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#-2"><span class="toc-number">7.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sigsegv-0xb-at-pc0x000000ffe18f46fc-pid5300-tid1099154321904"><span class="toc-number">8.</span> <span class="toc-text">SIGSEGV (0xb) at pc&#x3D;0x000000ffe18f46fc, pid&#x3D;5300, tid&#x3D;1099154321904</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#-3"><span class="toc-number">9.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#jre-version-openjdk-runtime-environment-80_25-b17-build-180_25-rc16-b17"><span class="toc-number">10.</span> <span class="toc-text">JRE version: OpenJDK Runtime Environment (8.0_25-b17) (build 1.8.0_25-rc16-b17)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#java-vm-openjdk-64-bit-server-vm-2525-b02-mixed-mode-linux-compressed-oops"><span class="toc-number">11.</span> <span class="toc-text">Java VM: OpenJDK 64-Bit Server VM (25.25-b02 mixed mode linux- compressed oops)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#problematic-frame"><span class="toc-number">12.</span> <span class="toc-text">Problematic frame:</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#j-62748-c2-scalatoolsasmclasswritergetlscalatoolsasmitemlscalatoolsasmitem-49-bytes-0x000000ffe18f46fc-0x000000ffe18f46a00x5c"><span class="toc-number">13.</span> <span class="toc-text">J 62748 C2 scala.tools.asm.ClassWriter.get(Lscala&#x2F;tools&#x2F;asm&#x2F;Item;)Lscala&#x2F;tools&#x2F;asm&#x2F;Item; (49 bytes) @ 0x000000ffe18f46fc [0x000000ffe18f46a0+0x5c]</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#-4"><span class="toc-number">14.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#failed-to-write-core-dump-core-dumps-have-been-disabled-to-enable-core-dumping-try-ulimit-c-unlimited-before-starting-java-again"><span class="toc-number">15.</span> <span class="toc-text">Failed to write core dump. Core dumps have been disabled. To enable core dumping, try &quot;ulimit -c unlimited&quot; before starting Java again</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#-5"><span class="toc-number">16.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#if-you-would-like-to-submit-a-bug-report-please-visit"><span class="toc-number">17.</span> <span class="toc-text">If you would like to submit a bug report, please visit:</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#httpbugreportsuncombugreportcrashjsp"><span class="toc-number">18.</span> <span class="toc-text">http:&#x2F;&#x2F;bugreport.sun.com&#x2F;bugreport&#x2F;crash.jsp</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%94-%E7%BC%96%E8%AF%91%E7%BB%93%E6%9E%9C"><span class="toc-number">19.</span> <span class="toc-text">五、编译结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AD-hadoop-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E6%B5%8B%E8%AF%95"><span class="toc-number">20.</span> <span class="toc-text">六、Hadoop 集群搭建测试</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%83-%E4%B8%8B%E8%BD%BD%E6%88%90%E5%93%81"><span class="toc-number">21.</span> <span class="toc-text">七、下载成品</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%AB-%E6%80%BB%E7%BB%93"><span class="toc-number">22.</span> <span class="toc-text">八、总结</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="红蓝一生伴" data-src="/images/avatar.jpg"><p class="name" itemprop="name">红蓝一生伴</p><div class="description" itemprop="description">喵喵喵</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">35</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">8</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">5</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3lvdXJuYW1l" title="https:&#x2F;&#x2F;github.com&#x2F;yourname"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;yourname"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;yourname"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPXlvdXJpZA==" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;yourid"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;about.me&#x2F;yourname"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/%E5%8D%8E%E4%B8%BA%E9%B2%B2%E9%B9%8F%E4%BA%91%E4%B9%8B%E6%88%91%E8%A7%81/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/%E9%BE%99%E6%97%8F%E7%BB%8F%E5%85%B8%E8%AF%AD%E5%BD%95/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/" title="操作系统知识点整理">操作系统知识点整理</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/tags/" title="Tags">Tags</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/note/" title="分类于 二进制杂谈">二进制杂谈</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/note/theme-shoka-doc/" title="分类于 Theme Shoka Documentation">Theme Shoka Documentation</a></div><span><a href="/computer-science/note/theme-shoka-doc/" title="Hexo主题Shoka &amp; multi-markdown-it渲染器使用说明">Hexo主题Shoka & multi-markdown-it渲染器使用说明</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/markdown/" title="Markdown Style test">Markdown Style test</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/gallery-post/" title="Gallery Post">Gallery Post</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/excerpts/" title="Excerpts">Excerpts</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/%E4%B8%AD%E6%96%87%E6%B8%AC%E8%A9%A6/" title="中文測試">中文測試</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/java/" title="分类于 Java">Java</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/java/course-1/" title="分类于 零基础学 Java 语言 - 浙江大学 - 翁恺">零基础学 Java 语言 - 浙江大学 - 翁恺</a></div><span><a href="/computer-science/java/course-1/week-2/" title="第2周 判断">第2周 判断</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/no-title/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/note/" title="分类于 二进制杂谈">二进制杂谈</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-science/note/theme-shoka-doc/" title="分类于 Theme Shoka Documentation">Theme Shoka Documentation</a></div><span><a href="/computer-science/note/theme-shoka-doc/dependents/" title="Step.1 依赖插件">Step.1 依赖插件</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">红蓝一生伴 @ 红蓝一生伴</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">153k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">2:19</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"龙芯3A2000移植Hadoop指南/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->